#!/usr/bin/python3

import sys
import rospy
import cv2
import numpy as np
import tf2_geometry_msgs
import tf2_ros
from sensor_msgs.msg import Image
from geometry_msgs.msg import PointStamped, Vector3, Pose
from cv_bridge import CvBridge, CvBridgeError
from visualization_msgs.msg import Marker, MarkerArray
from std_msgs.msg import ColorRGBA
import math
from color_recognition.msg import Int2dArray, IntList
from color_recognition.srv import ObjectColor, ObjectColorRequest
from ring_detection.msg import RingPoseColor

class The_Ring:
    def __init__(self):
        rospy.init_node('image_converter', anonymous=True)

        # An object we use for converting images between ROS format and OpenCV format
        self.bridge = CvBridge()

        # A help variable for holding the dimensions of the image
        self.dims = (0, 0, 0)

        # Marker array object used for visualizations
        self.marker_array = MarkerArray()
        self.marker_num = 1

        # Subscribe to the image and/or depth topic
        #self.image_sub = rospy.Subscriber("/camera/rgb/image_raw", Image, self.image_callback)
        #self.depth_sub = rospy.Subscriber("/camera/depth_registered/image_raw", Image, self.depth_callback)
        #self.depth_sub = rospy.Subscriber("/camera/depth/image_raw", Image, self.depth_callback)

        # Publiser for the visualization markers
        #self.markers_pub = rospy.Publisher('ring_markers', MarkerArray, queue_size=1000)
        self.pose_pub = rospy.Publisher('ring_pose', Pose, queue_size=1000)
        # Object we use for transforming between coordinate frames
        self.tf_buf = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buf)

        # service to predict color
        rospy.wait_for_service("ring_color")
        self.ring_color_client = rospy.ServiceProxy("ring_color", ObjectColor)

        self.ring_color_pub = rospy.Publisher('ring_pose_color', RingPoseColor, queue_size=100)


    def get_pose(self,e,dist, stamp):
        # Calculate the position of the detected ellipse

        k_f = 525 # kinect focal length in pixels

        elipse_x = self.dims[1] / 2 - e[0][0]
        elipse_y = self.dims[0] / 2 - e[0][1]

        angle_to_target = np.arctan2(elipse_x,k_f)

        # Get the angles in the base_link relative coordinate system
        x,y = dist*np.cos(angle_to_target), dist*np.sin(angle_to_target)

        # Define a stamped message for transformation - in the "camera rgb frame"
        point_s = PointStamped()
        point_s.point.x = -y
        point_s.point.y = 0
        point_s.point.z = x
        point_s.header.frame_id = "camera_rgb_optical_frame"
        #point_s.header.frame_id = "camera_depth_optical_frame"
        point_s.header.stamp = stamp

        # Get the point in the "map" coordinate system
        point_world = self.tf_buf.transform(point_s, "map")

        # Create a Pose object with the same position
        pose = Pose()
        pose.position.x = point_world.point.x
        pose.position.y = point_world.point.y
        pose.position.z = point_world.point.z

        #self.pose_pub.publish(pose)
        return pose


    def get_pose2(
            self,
            coords,
            dist,
            stamp,
    ):

        # Calculate the position of the detected face

        k_f = 554  # kinect focal length in pixels

        (x1, x2, y1, y2) = coords

        face_x = self.dims[1] / 2 - (x1 + x2) / 2.
        face_y = self.dims[0] / 2 - (y1 + y2) / 2.

        angle_to_target = np.arctan2(face_x, k_f)
        # print(angle_to_target)

        # Get the angles in the base_link relative coordinate system

        (x, y) = (dist * np.cos(angle_to_target), dist
                  * np.sin(angle_to_target))

        # ## Define a stamped message for transformation - directly in "base_link"
        # point_s = PointStamped()
        # point_s.point.x = x
        # point_s.point.y = y
        # point_s.point.z = 0.3
        # point_s.header.frame_id = "base_link"
        # point_s.header.stamp = rospy.Time(0)

        # Define a stamped message for transformation - in the "camera rgb frame"

        point_s = PointStamped()
        point_s.point.x = -y
        point_s.point.y = 0
        point_s.point.z = x
        point_s.header.frame_id = 'camera_rgb_optical_frame'
        point_s.header.stamp = stamp

        # Get the point in the "map" coordinate system

        try:
            point_world = self.tf_buf.transform(point_s, 'map')

            # Create a Pose object with the same position

            pose = Pose()
            pose.position.x = point_world.point.x
            pose.position.y = point_world.point.y
            pose.position.z = point_world.point.z
        except Exception as e:
            print(e)
            pose = None

        return pose
    """
    less than 1 = inside ellipse
    more than 1 = ouside ellipse
    """
    def insideOutside(self, h, k, x, y, a, b):
        # checking the equation of
        # ellipse with the given point
        p = ((math.pow((x - h), 2) / math.pow(a, 2)) +
            (math.pow((y - k), 2) / math.pow(b, 2)))
    
        return p
        
    def depth_callback(self):
        #print("got a DEPTH image")
        try:
            data = rospy.wait_for_message("/camera/depth/image_raw", Image)
            depth_image = self.bridge.imgmsg_to_cv2(data, "16UC1")
            #get float32
            depp = self.bridge.imgmsg_to_cv2(data, "32FC1")
        except CvBridgeError as e:
            print(e)
        try:
            cv_i = rospy.wait_for_message('/camera/rgb/image_raw', Image)
            #print("RGB stamp ", cv_i.header.stamp)
            #print("Depth stamp ", data.header.stamp)
            cv_rgb = self.bridge.imgmsg_to_cv2(cv_i, "rgb8")
            cv_image = self.bridge.imgmsg_to_cv2(cv_i, "bgr8")
        except Exception as e:
            print(e)
        # Set the dimensions of the image
        self.dims = depth_image.shape

        # Do the necessairy conversion so we can visuzalize it in OpenCV
        image_1 = depth_image / 65536.0 * 255
        image_1 =image_1/np.max(image_1)*255

        image_viz = np.array(image_1, dtype= np.uint8)
        
        # Binarize the image
        ret, thresh = cv2.threshold(image_viz, 50, 255, cv2.THRESH_BINARY)
        


        # Extract contours
        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)

        # Fit elipses to all extracted contours
        elps = []
        for cnt in contours:
            if cnt.shape[0] >= 20:
                ellipse = cv2.fitEllipse(cnt)
                elps.append(ellipse)


        # Find two elipses with same centers
        candidates = []
        for n in range(len(elps)):
            for m in range(n + 1, len(elps)):
                e1 = elps[n]
                e2 = elps[m]
                dist = np.sqrt(((e1[0][0] - e2[0][0]) ** 2 + (e1[0][1] - e2[0][1]) ** 2))
                if dist < 15:
                    candidates.append((e1,e2))

        # print("Processing is done! found", len(candidates), "candidates for rings")

        


        # Extract the depth from the depth image
        for c in candidates:

            # the centers of the ellipses
            e1 = c[0]
            e2 = c[1]


            # drawing the ellipses on the image
            #cv2.ellipse(cv_image, e1, (0, 255, 0), 2)
            #cv2.ellipse(cv_image, e2, (0, 255, 0), 2)

            size = (e1[1][0]+e1[1][1])/2
            center = (e1[0][1], e1[0][0])

            size2 = (e2[1][0]+e2[1][1])/2
            center2 = (e2[0][1], e2[0][0])

            x1 = int(center[0] - size / 2)
            x1 = x1 if x1 < int(center[0] - size2 / 2) else int(center[0] - size2 / 2)
            x2 = int(center[0] + size / 2)
            x2 = x2 if x2 > int(center[0] + size2 / 2) else int(center[0] + size2 / 2)
            x_min = x1 if x1>0 else 0
            x_max = x2 if x2<cv_image.shape[0] else cv_image.shape[0]

            y1 = int(center[1] - size / 2)
            y1 = y1 if y1 < int(center[1] - size2 / 2) else int(center[1] - size2 / 2) 
            y2 = int(center[1] + size / 2)
            y2 = y1 if y2 > int(center[1] + size2 / 2) else int(center[1] + size2 / 2)
            y_min = y1 if y1 > 0 else 0
            y_max = y2 if y2 < cv_image.shape[1] else cv_image.shape[1]

            #check in rgb img if there is ellipse
            povecaj_za = 15
            minnnX = x_min-povecaj_za if x_min-povecaj_za > 0 else x_min 
            maxxxX = x_max+povecaj_za if x_max+povecaj_za < cv_image.shape[0] else x_max
            minnnY = y_min-povecaj_za if y_min-povecaj_za > 0 else y_min
            maxxxY = y_max+povecaj_za if y_max+povecaj_za < cv_image.shape[1] else y_max
            color = self.find2elipses(cv_image[minnnX:maxxxX,minnnY:maxxxY])
            if(color == None):
                #print("not found")
                return
            # Get the time that the depth image was recieved
            depth_time = data.header.stamp

            #self.get_pose(e1, float(np.nanmean(depp[x_min:x_max,y_min:y_max])), depth_time)
            # getting all the poses for marker calculations
            poseMiddle = self.get_pose(e1, float(np.nanmedian(depp[x_min:x_max,y_min:y_max])), depth_time)

            x_center = int(x_min + (x_max - x_min) / 2)
            y_center = int(y_min + (y_max - y_min) / 2)

            left_x_1 = x_center-5 if x_center-5 > 0 else x_center
            left_x_2 = x_center+5 if x_center+5 < depp.shape[0] else depp.shape[0]
            left_y_2 = y_min+10 if y_min+10 < depp.shape[1] else depp.shape[1]
            right_y_2 = y_max+10 if y_max+10 < depp.shape[1] else depp.shape[1]


            #distanceLeft = float(np.nanmedian(depp[x_center-5:x_center+5, y_min:y_min+10]))
            #distanceRight = float(np.nanmedian(depp[x_center-5:x_center+5, y_max:y_max+10]))
            try:
                distanceLeft = float(np.nanmedian(depp[left_x_1:left_x_2, y_min:left_y_2]))
                distanceRight = float(np.nanmedian(depp[left_x_1:left_x_2, y_max:y_max+10]))
            except Exception as e:
                print(e)
                continue

            poseLeft = self.get_pose2((y_min,y_min+5,x_min,x_min+5), distanceLeft, depth_time)
            poseRight = self.get_pose2((y_max, y_max+5,x_min,x_min+5), distanceRight, depth_time)

            if poseMiddle is None or poseLeft is None or poseRight is None or \
                    not self.checkNan(poseMiddle) or not self.checkNan(poseLeft) or not self.checkNan(poseRight):
                continue

            """
            # getting the color of the ring
            color_list = []
            msg_list = Int2dArray()
            for i in range(x_min, x_max):
                for j in range(y_min, y_max):
                    p = self.insideOutside(center[0], center[1], i, j, size/2, size/2)
                    p2 = self.insideOutside(center2[0], center2[1], i, j, size2/2, size2/2)
                    if (p < 1 and p2 > 1) or (p > 1 and p2 < 1):    # or p == 1 or p2 == 1  
                        color_list.append(cv_image[i][j])
                        col = IntList()
                        col.elements = [cv_image[i][j][2], cv_image[i][j][1], cv_image[i][j][0]]
                        msg_list.lists.append(col)
            request = ObjectColorRequest()
            request.data = msg_list
            response = self.ring_color_client(request)
            color = response.color
            """
            print("Ring color:",color)
            # createing message to send to ring_markers
            message = RingPoseColor()
            message.poseMiddle = poseMiddle
            message.poseLeft = poseLeft
            message.poseRight = poseRight
            message.color = color

            self.ring_color_pub.publish(message)
        """
        if len(candidates)>0:
            print("OK?")
            cv2.imshow("Image window",cv_image[x_min:x_max,y_min:y_max])
            cv2.waitKey(1)
        """

    # find elipses where depth image says so
    def find2elipses(self, cv_image):
        # Tranform image to gayscale
        gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)

        #cv2.imshow("Image window gray",gray)
        #cv2.waitKey(1)

        # Do histogram equlization
        img = cv2.equalizeHist(gray)

        #cv2.imshow("Image equalizeHist gray",img)
        #cv2.waitKey(1)

        # Binarize the image
        #ret, thresh = cv2.threshold(img, 50, 255, 0)
        #ret, thresh = cv2.threshold(img, 200, 255, cv2.THRESH_BINARY)
        thresh = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)

        #cv2.imshow("Image equalizeHist thresh", thresh)
        #cv2.waitKey(1)
        #cv2.imshow("Image equalizeHist ret", ret)
        #cv2.waitKey(1)
        # Extract contours
        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)

        ploscina_slike = cv_image.shape[0] * cv_image.shape[1]

        # Example how to draw the contours
        # cv2.drawContours(img, contours, -1, (255, 0, 0), 3)
        #print(len(contours))
        # Fit elipses to all extracted contours
        elps = []
        for cnt in contours:
            #     print cnt
            #     print cnt.shape
            #print("shape ", cnt.shape[0])
            if cnt.shape[0] >= 20:
                ellipse = cv2.fitEllipse(cnt)
                elps.append(ellipse)
        #print("num of contours ", len(contours))

        # Find two elipses with same centers
        dist_min = 10000
        candidates = []
        for n in range(len(elps)):
            for m in range(n + 1, len(elps)):
                e1 = elps[n]
                e2 = elps[m]
                dist = np.sqrt(((e1[0][0] - e2[0][0]) ** 2 + (e1[0][1] - e2[0][1]) ** 2))
                #             print dist
                #print("dist ", dist)
                if dist < 8:
                    size = (e1[1][0]+e1[1][1])/2
                    size2 = (e2[1][0]+e2[1][1])/2
                    #print(abs(size-size2))
                    #print("shape: " + str(cv_image.shape))
                    #print(e1)
                    #print(e2)
                    #print("1 elipse plus size: " + str(e1[0][1]+size/2) + " " + str(e1[0][0]+size/2))
                    #print("2 elipse plus size: " + str(e2[0][1]+size2/2) + " " + str(e2[0][0]+size2/2))
                    #print("slika: " + str(cv_image.shape[0]) + " " + str(cv_image.shape[1]))
                    #print("woooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo")
                    #print("first axis: "+ str(abs((e1[0][1]+e1[1][1]/2)-(e2[0][1]+e2[1][1]/2))))
                    #print("first axis2: "+ str(abs((e1[0][1]-e1[1][1]/2)-(e2[0][1]-e2[1][1]/2))))
                    #print("second axis: " + str(abs((e1[0][0]+e1[1][0]/2) - (e2[0][0]+e2[1][0]/2))))
                    #print("second axis: " + str(abs((e1[0][0]-e1[1][0]/2) - (e2[0][0]-e2[1][0]/2))))
                    #print("ploscina slike: " + str(cv_image.shape[0] * cv_image.shape[1]))
                    #print("plosina1: " +str(3.14 * e1[1][0]/2 * e1[1][1]/2))
                    #print("ploscina2: " +str(3.14 * e2[1][0]/2 * e2[1][1]/2))
                    max_razlika = 9
                    if len(candidates)<1:
                        if (
                            abs(size-size2) < 50 and abs((e1[0][1]+e1[1][1]/2)-(e2[0][1]+e2[1][1]/2)) < max_razlika 
                            and abs((e1[0][0]+e1[1][0]/2) - (e2[0][0]+e2[1][0]/2)) < max_razlika
                            and abs((e1[0][1]-e1[1][1]/2)-(e2[0][1]-e2[1][1]/2)) < max_razlika
                            and abs((e1[0][0]-e1[1][0]/2) - (e2[0][0]-e2[1][0]/2)) < max_razlika
                            and (3.14 * e1[1][0]/2 * e1[1][1]/2) < ploscina_slike
                            and (3.14 * e2[1][0]/2 * e2[1][1]/2) < ploscina_slike
                            and abs(((3.14 * e1[1][0]/2 * e1[1][1]/2)  - (3.14 * e2[1][0]/2 * e2[1][1]/2))) < 1500
                            and (e1[1][0]/e1[1][1]) > 0.8
                            and (e2[1][0]/e2[1][1]) > 0.8
                            ):
                            candidates.append((e1,e2))
                            dist_min = dist
                    else:
                        if (
                            dist < dist_min and abs(size-size2) < 50 and abs((e1[0][1]+e1[1][1]/2)-(e2[0][1]+e2[1][1]/2)) < max_razlika 
                            and abs((e1[0][0]+e1[1][0]/2) - (e2[0][0]+e2[1][0]/2)) < max_razlika
                            and abs((e1[0][1]-e1[1][1]/2)-(e2[0][1]-e2[1][1]/2)) < max_razlika
                            and abs((e1[0][0]-e1[1][0]/2) - (e2[0][0]-e2[1][0]/2)) < max_razlika
                            and (3.14 * e1[1][0]/2 * e1[1][1]/2) < ploscina_slike
                            and (3.14 * e2[1][0]/2 * e2[1][1]/2) < ploscina_slike
                            and abs(((3.14 * e1[1][0]/2 * e1[1][1]/2)  - (3.14 * e2[1][0]/2 * e2[1][1]/2))) < 1500
                            and (e1[1][0]/e1[1][1]) > 0.8
                            and (e2[1][0]/e2[1][1]) > 0.8
                        ):
                            candidates[0] = (e1,e2)
                            dist_min = dist
        if len(candidates)<1:
            return None
        
        e1 = candidates[0][0]
        e2 = candidates[0][1]
        #print("ploscina slike: " + str(cv_image.shape[0] * cv_image.shape[1]))
        #print("plosina1: " +str(3.14 * e1[1][0]/2 * e1[1][1]/2))
        #print("ploscina2: " +str(3.14 * e2[1][0]/2 * e2[1][1]/2))
        size = (e1[1][0]+e1[1][1])/2
        #print("ratio1: " + str(e1[1][0]/e1[1][1]))
        center = (e1[0][1], e1[0][0])

        size2 = (e2[1][0]+e2[1][1])/2
        #print("ratio2: " + str(e2[1][0]/e2[1][1]))
        center2 = (e2[0][1], e2[0][0])

        # getting the color of the ring
        color_list = []
        msg_list = Int2dArray()
        for i in range(0, cv_image.shape[0]):
            for j in range(0, cv_image.shape[1]):
                p = self.insideOutside(center[0], center[1], i, j, size/2, size/2)
                p2 = self.insideOutside(center2[0], center2[1], i, j, size2/2, size2/2)
                if (p < 1 and p2 > 1) or (p > 1 and p2 < 1):    # or p == 1 or p2 == 1  
                    color_list.append(cv_image[i][j])
                    col = IntList()
                    col.elements = [cv_image[i][j][2], cv_image[i][j][1], cv_image[i][j][0]]
                    msg_list.lists.append(col)
        request = ObjectColorRequest()
        request.data = msg_list
        response = self.ring_color_client(request)
        color = response.color

        # drawing the ellipses on the image
        cv2.ellipse(cv_image, e1, (0, 255, 0), 2)
        cv2.ellipse(cv_image, e2, (0, 255, 0), 2)
        if len(candidates)>0:
            #print("OK?")
            cv2.imshow("Image window",cv_image)
            cv2.waitKey(1)
        return color
    
    # returns true if there is no Nan values
    def checkNan(self, pose):
        if math.isnan(pose.position.x) or math.isnan(pose.position.y) \
                or math.isnan(pose.position.z):
            return False
        else:
            return True

def main():

    ring_finder = The_Ring()

    rate = rospy.Rate(5)
    while not rospy.is_shutdown():
        ring_finder.depth_callback()
        rate.sleep()

    try:
        rospy.spin()
    except KeyboardInterrupt:
        print("Shutting down")

    cv2.destroyAllWindows()


if __name__ == '__main__':
    main()

